{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Nets: Convolution\n",
    "\n",
    "In this lab we try to build a model to detect handwritten digits. This lab should introduce you in the use of keras and should enable you to build and train your own CNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# nn\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten, Reshape, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# image manipulation\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we load our data set that is devided into a training and a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load digit dataset with training and test images\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this data set we have 10 different classes. Each data point in this data set is an image of resoution 28x28 and shows a handwirtten digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 10\n",
    "# dimension\n",
    "img_rows, img_cols = x_train[0].shape\n",
    "print('number of rows: ' + str(img_rows) + '; number of cols: ' + str(img_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better feeling for the data we take a look at the first 10 instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The data consists of images of digits, let's\n",
    "# have a look at the first 4 images, stored in the `images` attribute of the\n",
    "# dataset. For all images, we know which digit they represent: it is given in the 'target' of\n",
    "# the dataset.\n",
    "num_to_show = 10\n",
    "for i in range(num_to_show):\n",
    "    image = x_train[i]\n",
    "    label = y_train[i]\n",
    "    plt.subplot(2, num_to_show, i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title(str(label))\n",
    "plt.show()\n",
    "\n",
    "# print some statistics\n",
    "print('number of train images: ' + str(len(x_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exercise 1:</b>  \n",
    "Create a histogram showing the class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to reshape the training and test data so that a model created by keras can handle it. We do so by just adding an extra dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform data set\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Simple Neural Model</b>\n",
    "\n",
    "Our first simple model is a neural net with one hidden layer consisting of 512 hidden units and a ReLU activation function. To prevent overfitting a dropout layer is added after that. The input for this net is an image that is converted to a flat vector in the first layer. Please have a look at the architecture and try to understand the structure of this neural net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSimpleModel():\n",
    "    # simple model with dense layers\n",
    "    simpleModel = Sequential()\n",
    "    simpleModel.add(Flatten(input_shape=input_shape))\n",
    "    simpleModel.add(Dense(512, activation='relu'))\n",
    "    simpleModel.add(Dropout(0.2))\n",
    "    simpleModel.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "    simpleModel.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
    "    return simpleModel\n",
    "\n",
    "simpleModel = getSimpleModel()\n",
    "simpleModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Simple Convolutional Neural Net</b>\n",
    "\n",
    "The second neural net we are using is a convolutional neural net. This network consists of a convolutional layer a max pooling layer and a dense layer in the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# simple cnn\n",
    "def getCNNModel():\n",
    "    nb_filters_one = 32\n",
    "    nb_filters_two = 64\n",
    "    nb_conv = 3\n",
    "    nb_pool = 2\n",
    "    dense_size = 128\n",
    "    cnnModel = Sequential()\n",
    "    cnnModel.add(Conv2D(nb_filters_one, kernel_size=(nb_conv, nb_conv),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    cnnModel.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "    cnnModel.add(Dropout(0.25))\n",
    "    cnnModel.add(Flatten())\n",
    "    cnnModel.add(Dense(dense_size, activation='relu'))\n",
    "    cnnModel.add(Dropout(0.5))\n",
    "    cnnModel.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "    cnnModel.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
    "    return cnnModel\n",
    "\n",
    "cnnModel = getCNNModel()\n",
    "cnnModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exercise 2:</b>  \n",
    "Compare the two different network architectures. What can you say about the number of trainable parameters? Which neural net will probably work better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Answer:</b>\n",
    "number of parameter in cnn is higher. and cnn will probably work better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the integer label for the neural net training we have to encode them in a one-hot-encoding way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oneHotLabelTrain = np_utils.to_categorical(y_train, nb_classes)\n",
    "oneHotLabelTest  = np_utils.to_categorical(y_test,  nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train both models and save the training and testing accuracies for the different epochs in a callback. This can really take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "simpleModel = getSimpleModel()\n",
    "learnHistSimple = simpleModel.fit(x_train,oneHotLabelTrain,validation_data=(x_test,oneHotLabelTest),\n",
    "                                  batch_size=batch_size,\n",
    "                                  epochs=10)\n",
    "cnnModel = getCNNModel()\n",
    "learnHistCNN    = cnnModel.fit(x_train,oneHotLabelTrain,validation_data=(x_test,oneHotLabelTest),\n",
    "                                  batch_size=batch_size,\n",
    "                                  epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(learnHistCNN.history)\n",
    "print(np.arange(1,numEpochs+1,1).shape)\n",
    "print(np.array(learnHistSimple.history['loss']).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exercise 3:</b>  \n",
    "Plot the learning curves for the two neural nets, showing the training and testing loss over the number of epochs. What are the learning curves telling you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the results for the neural net (simple model) are much worse than the results for the CNN.\n",
    "\n",
    "<b>Excercise 4:</b>\n",
    "\n",
    "Normalize the input data so that all values are between 0 and 1. After that, retrain the simple model. Are the results better? Can you explain the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "# normalize images\n",
    "x_train_rescaled = \n",
    "x_test_rescaled = \n",
    "\n",
    "# retrain model\n",
    "batch_size = 128\n",
    "simpleModel = getSimpleModel()\n",
    "learnHistSimple = simpleModel.fit(x_train_rescaled,oneHotLabelTrain,validation_data=(x_test_rescaled,oneHotLabelTest),\n",
    "                                  batch_size=batch_size,\n",
    "                                  epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise 5:</b>\n",
    "    \n",
    "Write a function that randomly places the digits from the input data on a 2-dimensional image of size 28x28. Do this by firstly resizing the image to the size 14x14 and than placing this digit on a grid of 28x28. After that the data set should look like shown in the image above.\n",
    "\n",
    "<img src=\"files/non-centered.png\",width=600,height=600>\n",
    "\n",
    "<b>Hint</b>: Maybe the function cv2.resize(...) could be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_random_noise(inputData):\n",
    "    out_data = np.zeros(inputData.shape)\n",
    "    # YOUR CODE GOES HERE\n",
    "    \n",
    "    \n",
    "    \n",
    "    return out_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can have a look at the new data set of non-centered digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try to create a more realistic data set\n",
    "x_train_non_centered = add_random_noise(x_train)\n",
    "x_test_non_centered = add_random_noise(x_test)\n",
    "\n",
    "for i in range(50):\n",
    "    image = x_train_non_centered[i]\n",
    "    image = image.reshape([img_rows,img_cols])\n",
    "    label = y_train[i]\n",
    "    plt.subplot(5, 10, i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title(label)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# scale data\n",
    "x_train_non_centered /= 255.\n",
    "x_test_non_centered /= 255.\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train_non_centered = x_train_non_centered.reshape(x_train_non_centered.shape[0], 1, img_rows, img_cols)\n",
    "    x_test_non_centered = x_test_non_centered.reshape(x_test_non_centered.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train_non_centered = x_train_non_centered.reshape(x_train_non_centered.shape[0], img_rows, img_cols, 1)\n",
    "    x_test_non_centered = x_test_non_centered.reshape(x_test_non_centered.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise 6:</b>\n",
    "    \n",
    "Train the simple nn and the cnn on this new data set for 10 epochs and compare the trainng and testing results with each other. What conclusions can you draw?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "# YOUR CODE GOES HERE\n",
    "simpleModel = getSimpleModel()\n",
    "cnnModel = getCNNModel()\n",
    "learnHistSimple = \n",
    "learnHistCNN = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Additional Excercise</b>\n",
    "\n",
    "Try to build a model that is able to get better classification results on the non-centered data set."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
